{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 7. Metodología de Machine Learning\n",
        "\n",
        "Este documento presenta la metodología propuesta para el análisis de machine learning, incluyendo la selección de modelos, algoritmos, justificación de hiperparámetros y técnicas de validación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7.1. Selección del Modelo\n",
        "\n",
        "### Problema a Resolver\n",
        "\n",
        "El objetivo principal es **predecir el éxito académico** de los estudiantes en el programa Talento Tech Bogotá. Este es un problema de **clasificación binaria** donde:\n",
        "\n",
        "- **Variable objetivo**: exito_academico\n",
        "  - Clase 0: Estudiante no completó exitosamente (NO APROBADO, INACTIVO)\n",
        "  - Clase 1: Estudiante completó exitosamente (FORMADO)\n",
        "\n",
        "- **Variables predictoras**: Características demográficas, socioeconómicas, académicas y de rendimiento inicial\n",
        "\n",
        "### Justificación del Tipo de Modelo\n",
        "\n",
        "Se propone un modelo de **clasificación supervisada** porque:\n",
        "\n",
        "1. **Tenemos datos etiquetados**: Conocemos el resultado final de cada estudiante\n",
        "2. **Objetivo claro**: Predecir si un estudiante tendrá éxito o no\n",
        "3. **Aplicación práctica**: Permitiría identificar estudiantes en riesgo tempranamente\n",
        "4. **Toma de decisiones**: Los resultados pueden guiar intervenciones pedagógicas\n",
        "\n",
        "### Consideraciones Importantes\n",
        "\n",
        "- **Balance de clases**: Es necesario analizar si existe desbalance entre estudiantes exitosos y no exitosos\n",
        "- **Features relevantes**: Debemos identificar qué características son más predictivas del éxito\n",
        "- **Interpretabilidad**: El modelo debe ser explicable para entender qué factores influyen más"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7.2. Algoritmos y Técnicas Propuestas\n",
        "\n",
        "### Algoritmos Seleccionados\n",
        "\n",
        "Se propone comparar dos algoritmos complementarios:\n",
        "\n",
        "#### 1. Random Forest (Bosque Aleatorio)\n",
        "\n",
        "**Descripción**: Ensemble de múltiples árboles de decisión que votan para la clasificación final.\n",
        "\n",
        "**Ventajas**:\n",
        "- Maneja bien relaciones no lineales entre variables\n",
        "- Robusto ante outliers y datos ruidosos\n",
        "- Proporciona importancia de variables\n",
        "- Menor riesgo de sobreajuste que un árbol individual\n",
        "- No requiere normalización de datos\n",
        "\n",
        "**Desventajas**:\n",
        "- Menos interpretable que modelos lineales\n",
        "- Mayor costo computacional\n",
        "- Puede ser difícil de optimizar\n",
        "\n",
        "**Por qué es apropiado**: Las relaciones entre variables educativas, demográficas y de rendimiento suelen ser complejas y no lineales. Random Forest puede capturar estas interacciones.\n",
        "\n",
        "#### 2. Regresión Logística\n",
        "\n",
        "**Descripción**: Modelo lineal que estima la probabilidad de pertenencia a una clase.\n",
        "\n",
        "**Ventajas**:\n",
        "- Altamente interpretable (coeficientes muestran efecto de cada variable)\n",
        "- Rápido de entrenar\n",
        "- Funciona bien con conjuntos de datos pequeños/medianos\n",
        "- Proporciona probabilidades calibradas\n",
        "- Menos propenso al sobreajuste\n",
        "\n",
        "**Desventajas**:\n",
        "- Asume relaciones lineales\n",
        "- Puede no capturar interacciones complejas\n",
        "- Sensible a multicolinealidad\n",
        "\n",
        "**Por qué es apropiado**: Sirve como baseline interpretable y permite entender el efecto directo de cada factor en el éxito académico.\n",
        "\n",
        "### Estrategia de Comparación\n",
        "\n",
        "Se entrenará ambos modelos con los mismos datos y se compararán usando múltiples métricas para seleccionar el más apropiado según el contexto del problema."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7.3. Justificación de Hiperparámetros\n",
        "\n",
        "### Concepto de Hiperparámetros\n",
        "\n",
        "Los hiperparámetros son configuraciones del algoritmo que no se aprenden de los datos, sino que deben ser definidas antes del entrenamiento. Afectan directamente el rendimiento y la capacidad de generalización del modelo.\n",
        "\n",
        "### Hiperparámetros Propuestos para Random Forest\n",
        "\n",
        "#### 1. n_estimators (Número de árboles)\n",
        "- **Valores a probar**: 50, 100, 200\n",
        "- **Justificación**: Más árboles generalmente mejoran el rendimiento pero aumentan el costo computacional. Se propone probar un rango moderado.\n",
        "- **Efecto**: Más árboles → mayor estabilidad y precisión, pero mayor tiempo de entrenamiento\n",
        "\n",
        "#### 2. max_depth (Profundidad máxima)\n",
        "- **Valores a probar**: 5, 10, 15, None (sin límite)\n",
        "- **Justificación**: Controla la complejidad de cada árbol y previene sobreajuste\n",
        "- **Efecto**: Mayor profundidad → puede capturar patrones más complejos, pero riesgo de sobreajuste\n",
        "\n",
        "#### 3. min_samples_split (Mínimo de muestras para dividir)\n",
        "- **Valores a probar**: 2, 5, 10\n",
        "- **Justificación**: Controla cuándo un nodo puede dividirse, afectando la regularización\n",
        "- **Efecto**: Valores mayores → modelos más conservadores y menos sobreajustados\n",
        "\n",
        "#### 4. min_samples_leaf (Mínimo de muestras por hoja)\n",
        "- **Valores a probar**: 1, 2, 4\n",
        "- **Justificación**: Evita hojas con muy pocas muestras que pueden ser ruido\n",
        "- **Efecto**: Valores mayores → árboles más suaves y generalizables\n",
        "\n",
        "### Hiperparámetros Propuestos para Regresión Logística\n",
        "\n",
        "#### 1. C (Regularización)\n",
        "- **Valores a probar**: 0.01, 0.1, 1, 10, 100\n",
        "- **Justificación**: Controla la fuerza de la regularización (inverso de lambda)\n",
        "- **Efecto**: C pequeño → mayor regularización, modelo más simple\n",
        "\n",
        "#### 2. penalty (Tipo de regularización)\n",
        "- **Valores a probar**: 'l1' (Lasso), 'l2' (Ridge)\n",
        "- **Justificación**: L1 puede hacer selección de features, L2 reduce magnitud de coeficientes\n",
        "- **Efecto**: L1 → puede llevar coeficientes a 0, L2 → solo los reduce\n",
        "\n",
        "### Método de Optimización: Grid Search con Cross-Validation\n",
        "\n",
        "**Proceso propuesto**:\n",
        "1. Definir una grilla de combinaciones de hiperparámetros\n",
        "2. Para cada combinación:\n",
        "   - Entrenar el modelo con validación cruzada (5 folds)\n",
        "   - Calcular métrica de rendimiento promedio\n",
        "3. Seleccionar la combinación con mejor rendimiento\n",
        "4. Evaluar en conjunto de prueba independiente\n",
        "\n",
        "**Métrica de optimización sugerida**: F1-Score (balance entre precisión y recall)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7.4. Validación Cruzada y Técnicas de Evaluación\n",
        "\n",
        "### Estrategia de Partición de Datos\n",
        "\n",
        "#### División Train-Test\n",
        "- **Entrenamiento**: 80% de los datos\n",
        "- **Prueba**: 20% de los datos\n",
        "- **Estratificación**: Mantener proporción de clases en ambos conjuntos\n",
        "- **Semilla aleatoria fija**: Para reproducibilidad\n",
        "\n",
        "**Justificación**: Esta división 80/20 es estándar y proporciona suficientes datos para entrenar mientras reserva una porción representativa para evaluación final.\n",
        "\n",
        "### Validación Cruzada (Cross-Validation)\n",
        "\n",
        "#### K-Fold Estratificado (k=5)\n",
        "\n",
        "**Proceso**:\n",
        "1. Dividir datos de entrenamiento en 5 particiones (folds)\n",
        "2. Para cada fold:\n",
        "   - Usar 4 folds para entrenar\n",
        "   - Usar 1 fold para validar\n",
        "3. Repetir hasta que cada fold haya sido usado para validación\n",
        "4. Promediar resultados de los 5 folds\n",
        "\n",
        "**Ventajas**:\n",
        "- Utiliza todos los datos para entrenamiento y validación\n",
        "- Reduce varianza en la estimación del rendimiento\n",
        "- Menos sensible a la partición particular de datos\n",
        "- Estratificación mantiene proporción de clases\n",
        "\n",
        "**Justificación**: 5 folds es un balance entre uso eficiente de datos y costo computacional. La estratificación es crítica con clases potencialmente desbalanceadas.\n",
        "\n",
        "### Métricas de Evaluación\n",
        "\n",
        "#### Métricas Principales\n",
        "\n",
        "1. **Accuracy (Exactitud)**\n",
        "   - Proporción de predicciones correctas\n",
        "   - Útil cuando las clases están balanceadas\n",
        "   - Fórmula: (VP + VN) / Total\n",
        "\n",
        "2. **Precision (Precisión)**\n",
        "   - De los que predijimos como éxito, ¿cuántos realmente lo fueron?\n",
        "   - Importante si el costo de falsos positivos es alto\n",
        "   - Fórmula: VP / (VP + FP)\n",
        "\n",
        "3. **Recall (Sensibilidad)**\n",
        "   - De los que realmente tuvieron éxito, ¿cuántos identificamos?\n",
        "   - Importante si el costo de falsos negativos es alto\n",
        "   - Fórmula: VP / (VP + FN)\n",
        "\n",
        "4. **F1-Score**\n",
        "   - Media armónica de precisión y recall\n",
        "   - Útil con clases desbalanceadas\n",
        "   - Fórmula: 2 × (Precision × Recall) / (Precision + Recall)\n",
        "\n",
        "#### Matriz de Confusión\n",
        "\n",
        "Se propone analizar la matriz de confusión para entender:\n",
        "- **Verdaderos Positivos (VP)**: Estudiantes exitosos correctamente identificados\n",
        "- **Verdaderos Negativos (VN)**: Estudiantes no exitosos correctamente identificados\n",
        "- **Falsos Positivos (FP)**: Predijimos éxito pero no lo tuvieron\n",
        "- **Falsos Negativos (FN)**: No predijimos éxito pero sí lo tuvieron\n",
        "\n",
        "#### Curva ROC y AUC\n",
        "\n",
        "- **ROC (Receiver Operating Characteristic)**: Muestra trade-off entre tasa de verdaderos positivos y falsos positivos\n",
        "- **AUC (Area Under Curve)**: Métrica resumen de la capacidad discriminativa del modelo\n",
        "  - AUC = 1.0: Clasificador perfecto\n",
        "  - AUC = 0.5: Clasificador aleatorio\n",
        "\n",
        "### Manejo de Desbalance de Clases (si aplica)\n",
        "\n",
        "Si existe desbalance significativo entre clases, se propone:\n",
        "\n",
        "#### Técnicas de Re-muestreo\n",
        "\n",
        "1. **SMOTE (Synthetic Minority Over-sampling)**\n",
        "   - Crea ejemplos sintéticos de la clase minoritaria\n",
        "   - Interpola entre ejemplos cercanos\n",
        "   - Previene sobreajuste vs duplicación simple\n",
        "\n",
        "2. **Random Under-sampling**\n",
        "   - Reduce ejemplos de la clase mayoritaria\n",
        "   - Más rápido pero pierde información\n",
        "\n",
        "3. **Combinación (SMOTETomek)**\n",
        "   - SMOTE para sobre-muestrear minoría\n",
        "   - Tomek links para limpiar ruido en frontera\n",
        "\n",
        "#### Pesos de Clase\n",
        "\n",
        "- Asignar mayor peso a la clase minoritaria durante entrenamiento\n",
        "- Parámetro class_weight='balanced' ajusta automáticamente\n",
        "\n",
        "**Justificación**: El desbalance puede hacer que el modelo simplemente prediga la clase mayoritaria, ignorando la minoría."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resumen de la Metodología Propuesta\n",
        "\n",
        "### Pipeline Completo\n",
        "\n",
        "1. **Preparación de Datos**\n",
        "   - Dividir en train (80%) y test (20%) con estratificación\n",
        "   - Aplicar re-muestreo si hay desbalance\n",
        "\n",
        "2. **Entrenamiento Inicial**\n",
        "   - Entrenar Random Forest y Regresión Logística con parámetros default\n",
        "   - Evaluar con validación cruzada (5-fold estratificado)\n",
        "   - Comparar métricas base\n",
        "\n",
        "3. **Optimización de Hiperparámetros**\n",
        "   - Aplicar Grid Search con CV al mejor modelo base\n",
        "   - Buscar combinación óptima de hiperparámetros\n",
        "   - Re-entrenar con mejores parámetros\n",
        "\n",
        "4. **Evaluación Final**\n",
        "   - Evaluar modelo optimizado en conjunto de prueba\n",
        "   - Analizar matriz de confusión\n",
        "   - Calcular todas las métricas\n",
        "   - Interpretar importancia de features (Random Forest) o coeficientes (Regresión Logística)\n",
        "\n",
        "5. **Análisis de Resultados**\n",
        "   - Identificar variables más predictivas\n",
        "   - Evaluar viabilidad de implementación\n",
        "   - Proponer recomendaciones\n",
        "\n",
        "### Criterios de Éxito\n",
        "\n",
        "El modelo será considerado exitoso si:\n",
        "- **F1-Score > 0.70**: Balance adecuado entre precisión y recall\n",
        "- **Recall > 0.65**: Identifica al menos 65% de estudiantes en riesgo\n",
        "- **AUC > 0.75**: Buena capacidad discriminativa\n",
        "- **Interpretabilidad**: Variables importantes son accionables\n",
        "\n",
        "### Consideraciones Éticas y Prácticas\n",
        "\n",
        "- El modelo debe ser justo y no discriminar por género, etnia o estrato\n",
        "- Las predicciones deben usarse para apoyar, no excluir estudiantes\n",
        "- Debe actualizarse periódicamente con nuevos datos\n",
        "- Los resultados deben comunicarse claramente a los stakeholders\n",
        "\n",
        "---\n",
        "\n",
        "**Nota Final**: Esta metodología proporciona un marco robusto y sistemático para predecir el éxito académico. La implementación práctica requeriría ajustes según los resultados del análisis exploratorio y las características específicas del conjunto de datos."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
